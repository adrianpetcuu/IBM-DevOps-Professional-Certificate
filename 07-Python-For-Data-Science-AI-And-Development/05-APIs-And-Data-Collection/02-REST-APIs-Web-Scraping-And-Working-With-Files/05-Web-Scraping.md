# ğŸ•¸ï¸ Web Scraping Ã®n Python â€“ Ghid Complet

## ğŸ“– Introducere

**Web scraping** este procesul de colectare automatÄƒ a datelor din paginile web.  
Ãntr-o lume dominatÄƒ de informaÈ›ie, web scraping-ul oferÄƒ o metodÄƒ eficientÄƒ de extragere a datelor nestructurate (HTML, XML) È™i transformarea lor Ã®ntr-un format structurat (CSV, JSON, Excel, baze de date).

---

## ğŸŒ Cum funcÈ›ioneazÄƒ Web Scraping-ul

CÃ¢nd accesezi o paginÄƒ web, browserul tÄƒu trimite o cerere HTTP cÄƒtre serverul site-ului. Serverul rÄƒspunde cu un fiÈ™ier HTML care conÈ›ine tot conÈ›inutul paginii â€” text, linkuri, imagini, tabele etc.  
Prin web scraping, folosim programe Python pentru a:
1. **DescÄƒrca** conÈ›inutul HTML (cu `requests` sau `urllib`)
2. **Analiza** structura HTML (cu `BeautifulSoup` sau `lxml`)
3. **Extrage** informaÈ›iile dorite (titluri, tabele, linkuri etc.)
4. **Salva** datele Ã®ntr-un format util (CSV, JSON, Pandas DataFrame)

---

## ğŸ§  NoÈ›iuni de bazÄƒ HTML

Pentru a face scraping eficient, trebuie sÄƒ Ã®nÈ›elegi structura HTML.

### ğŸ”¹ Exemple de elemente HTML:
```html
<html>
  <head><title>Pagina mea</title></head>
  <body>
    <h1>Bun venit!</h1>
    <p id="intro">Aceasta este o paginÄƒ exemplu.</p>
    <a href="https://www.example.com">ApasÄƒ aici</a>
  </body>
</html>
```

### ğŸ”¸ Elemente importante:
- `<tag>` â†’ indicÄƒ Ã®nceputul unui element HTML
- `</tag>` â†’ indicÄƒ sfÃ¢rÈ™itul elementului
- `<a href="...">` â†’ defineÈ™te un **link**
- `<p>` â†’ defineÈ™te un **paragraf**
- `<table>` â†’ defineÈ™te un **tabel**

---

## ğŸ§° Biblioteci Python pentru Web Scraping

### 1ï¸âƒ£ **Requests**
FolositÄƒ pentru a descÄƒrca conÈ›inutul unei pagini web.

```python
import requests

url = "https://www.example.com"
response = requests.get(url)

print(response.status_code)  # 200 Ã®nseamnÄƒ succes
print(response.text[:500])   # primele 500 caractere din HTML
```

### 2ï¸âƒ£ **BeautifulSoup**
FolositÄƒ pentru analizarea È™i extragerea datelor din HTML.

```python
from bs4 import BeautifulSoup
import requests

url = "https://www.example.com"
page = requests.get(url)
soup = BeautifulSoup(page.content, "html.parser")

print(soup.title)               # titlul paginii
print(soup.find_all('p'))       # toate paragrafele
print(soup.find('a')['href'])   # primul link
```

### 3ï¸âƒ£ **Pandas**
Poate extrage direct tabele HTML Ã®n DataFrame-uri.

```python
import pandas as pd

url = "https://en.wikipedia.org/wiki/List_of_largest_banks"
tables = pd.read_html(url)
df = tables[0]
print(df.head())
```

### 4ï¸âƒ£ **Selenium**
FolositÄƒ pentru a controla un browser (ex. Chrome, Firefox). Poate accesa pagini dinamice generate de JavaScript.

```python
from selenium import webdriver

driver = webdriver.Chrome()
driver.get("https://www.example.com")

print(driver.title)
driver.quit()
```

### 5ï¸âƒ£ **Scrapy**
Framework avansat pentru crawling È™i colectare de date la scarÄƒ mare.

```python
import scrapy

class QuotesSpider(scrapy.Spider):
    name = "quotes"
    start_urls = ['http://quotes.toscrape.com/tag/humor/']

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {'quote': quote.css('span.text::text').get()}
```

---

## âš™ï¸ Bune practici È™i eticÄƒ Ã®n Web Scraping

âœ… RespectÄƒ **termenii È™i condiÈ›iile** site-ului.  
âœ… VerificÄƒ fiÈ™ierul `robots.txt` (ex. `https://site.com/robots.txt`).  
âœ… Nu trimite cereri prea frecvent (foloseÈ™te `time.sleep()` Ã®ntre cereri).  
âœ… Nu copia sau redistribui conÈ›inut protejat de drepturi de autor.  
âœ… IdentificÄƒ-te clar Ã®n antetul HTTP (ex. `User-Agent`).

---

## ğŸš¨ Erori comune È™i soluÈ›ii

| ProblemÄƒ | CauzÄƒ | SoluÈ›ie |
|-----------|--------|----------|
| `403 Forbidden` | Site-ul blocheazÄƒ cererile automate | AdaugÄƒ un User-Agent Ã®n header |
| `NoneType` la `find()` | Elementul nu existÄƒ Ã®n HTML | VerificÄƒ cu `print(soup.prettify())` |
| Pagina nu se Ã®ncarcÄƒ complet | ConÈ›inut dinamic (JavaScript) | FoloseÈ™te Selenium Ã®n loc de Requests |
| Datele sunt Ã®ntr-un iframe | Pagina conÈ›ine alte URL-uri | AcceseazÄƒ direct linkul iframe-ului |

Exemplu de User-Agent:

```python
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
requests.get(url, headers=headers)
```

---

## ğŸ§¼ CurÄƒÈ›area È™i procesarea datelor extrase

DupÄƒ scraping, datele pot fi â€murdareâ€. PoÈ›i folosi:

```python
import pandas as pd

df['col'] = df['col'].str.strip()          # eliminÄƒ spaÈ›iile
df['col'] = df['col'].str.replace('$','')  # eliminÄƒ caractere inutile
df.dropna(inplace=True)                    # eliminÄƒ valorile lipsÄƒ
```

---

## ğŸ Concluzie

Web Scraping este o tehnicÄƒ esenÈ›ialÄƒ pentru analiÈ™tii È™i dezvoltatorii de date.  
Prin combinarea bibliotecilor Python â€” `requests`, `BeautifulSoup`, `pandas`, `selenium` â€” putem transforma internetul Ã®ntr-o sursÄƒ vastÄƒ de informaÈ›ii structurate.  
TotuÈ™i, este important sÄƒ practicÄƒm **scraping responsabil È™i etic**, pentru a respecta drepturile de autor È™i stabilitatea serverelor.

---
